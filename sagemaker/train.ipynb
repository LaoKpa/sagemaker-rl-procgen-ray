{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Notebook for ProcGen Starter Kit with Single Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"config\", \"sagemaker_config.yaml\")) as f:\n",
    "    sagemaker_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.session.Session()\n",
    "s3_bucket = sagemaker_config[\"S3_BUCKET\"]\n",
    "\n",
    "s3_output_path = 's3://{}/'.format(s3_bucket)\n",
    "print(\"S3 bucket path: {}\".format(s3_output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'sm-ray-procgen'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training instance type and computational resources\n",
    "\n",
    "By default (`local_mode=False`) launch a separate instance for training and debug using the AWS CloudWatch to monitor the logs for the training instance. \n",
    "If you want to train on the same instance as your notebook for quick debugging, then set `local_mode=True`. \n",
    "\n",
    "The recommended instances include with cost per hour as of September, 1, 2020 are:\n",
    "* `ml.c5.4xlarge` $0.952 per hour (16 vCPU)\n",
    "\n",
    "* `ml.g4dn.4xlarge` $1.686 per hour (1 GPU, 16 vCPU)\n",
    "\n",
    "* `ml.p3.2xlarge` $4.284 per hour (1 GPU, 8 vCPU)\n",
    "\n",
    "After you choose your instance type, make sure the edit the resources in `source\\train-sagemaker.py`. For example, with `ml.p3.2xlarge`, you have 1 GPU and 8 vCPUs. The corresponding resources in `source\\train-sagemaker.py` should be set as for `ray` as `\n",
    "\n",
    "```\n",
    "    def _get_ray_config(self):\n",
    "        return {\n",
    "            \"ray_num_cpus\": 8, # adjust based on selected instance type\n",
    "            \"ray_num_gpus\": 1,\n",
    "            \"eager\": False,\n",
    "             \"v\": True, # requried for CW to catch the progress\n",
    "        }\n",
    "``` \n",
    "and for `rrlib` need to use 1 vCPU for driver (\"num_workers\": 7) and 1 GPU (\"num_gpus\": 1) for policy training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change local_mode to True if you want to do local training within this Notebook instance\n",
    "# Otherwise, we'll spin-up a SageMaker training instance to handle the training\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = 'local'\n",
    "else:\n",
    "    instance_type = sagemaker_config[\"CPU_TRAINING_INSTANCE\"]\n",
    "    \n",
    "# If training locally, do some Docker housekeeping..\n",
    "if local_mode:\n",
    "    !/bin/bash source/common/setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the training code\n",
    "\n",
    "The training code is written in the file `train-sagemaker.py` which is uploaded in the /source directory.\n",
    "\n",
    "#### *Warning: Confirm that the GPU and CPU resources are configured correctly for your instance type as described above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train-sagemaker.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the RL model using the Python SDK Script mode\n",
    "\n",
    "If you are using local mode, the training will run on the notebook instance. \n",
    "\n",
    "When using SageMaker for training, you can select a GPU or CPU instance. The RLEstimator is used for training RL jobs.\n",
    "\n",
    "1. Specify the source directory where the environment, presets and training code is uploaded.\n",
    "2. Specify the entry point as the training code\n",
    "3. Specify the custom image to be used for the training environment.\n",
    "4. Define the training parameters such as the instance count, job name, S3 path for output and job name.\n",
    "5. Define the metrics definitions that you are interested in capturing in your logs. These can also be visualized in CloudWatch and SageMaker Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*[Choose](https://github.com/aws/sagemaker-rl-container#rl-images-provided-by-sagemaker) which docker image to use based on the instance type.* For this notebook, it has to be a container with Ray 0.8.5 and TensorFlow to be consistent with the AICrowd ProcGen starter kit. If you prefer to use PyTorch, then you would need to substitute for the corresponding container listed on Amazon SageMaker Reinforcement Learning documentation. In addition, you will need to ensure your starter kit is modified to train using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_or_gpu = 'gpu' if instance_type.startswith('ml.p') else 'cpu'\n",
    "aws_region = boto3.Session().region_name\n",
    "custom_image_name = \"462105765813.dkr.ecr.%s.amazonaws.com/sagemaker-rl-ray-container:ray-0.8.5-tf-%s-py36\" % (aws_region, cpu_or_gpu)\n",
    "custom_image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to define metrics to be displayed in the logs. The challenge has requirements on the number of steps and uses mean episode reward to rank various solutions. For details, refer to the AICrowd challange website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions =  [\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episodes_total', 'Regex': 'episodes_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'num_steps_trained', 'Regex': 'num_steps_trained: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'timesteps_total', 'Regex': 'timesteps_total: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "    {'Name': 'training_iteration', 'Regex': 'training_iteration: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "\n",
    "    {'Name': 'episode_reward_max', 'Regex': 'episode_reward_max: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_mean', 'Regex': 'episode_reward_mean: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'}, \n",
    "    {'Name': 'episode_reward_min', 'Regex': 'episode_reward_min: ([-+]?[0-9]*[.]?[0-9]+([eE][-+]?[0-9]+)?)'},\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the RL estimator\n",
    "\n",
    "There are 16 environments to choose from. You can run the RL estimator on multiple environments by proving a list of environments as well. The RL estimator will start the training job. This will take longer compared to the above cells, be patient. You can monitor the status of your training job from the console as well, go to Amazon SageMaker > Training jobs. The most recent job will be at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which procgen environments to run in `envs_to_run`\n",
    "'''\n",
    "envs_to_run = [\"coinrun\", \"bigfish\", \"bossfight\", \"caveflyer\",\n",
    "               \"chaser\", \"climber\", \"coinrun\", \"dodgeball\",\n",
    "               \"fruitbot\", \"heist\", \"jumper\", \"leaper\", \"maze\",\n",
    "               \"miner\", \"ninja\", \"plunder\", \"starpilot\"]\n",
    "'''\n",
    "\n",
    "envs_to_run = [\"coinrun\", \"bigfish\", \"bossfight\"]\n",
    "\n",
    "config_file_location = \"experiments/procgen-starter-example.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env in envs_to_run:\n",
    "    estimator = RLEstimator(entry_point=\"train-sagemaker.py\",\n",
    "                            source_dir='source',\n",
    "                            dependencies=[\"source/utils\", \"source/common/\", \"neurips2020-procgen-starter-kit/\"],\n",
    "                            image_name=custom_image_name,\n",
    "                            role=role,\n",
    "                            train_instance_type=instance_type,\n",
    "                            train_instance_count=1,\n",
    "                            output_path=s3_output_path,\n",
    "                            base_job_name=job_name_prefix + \"-\" + env,\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            hyperparameters={\n",
    "                                #\"rl.training.upload_dir\": s3_output_path,\n",
    "                                \"rl.training.config.env_config.env_name\": env,\n",
    "                                #\"config_file\": config_file_location\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    estimator.fit(wait=False)\n",
    "    \n",
    "    print(estimator.latest_training_job.job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAAAITTTTT... not more than 2 hours "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "Download the model from S3 and perform several rollout steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize algorithm metrics for training\n",
    "\n",
    "There are several options to visualize algorithm metrics. A detailed blog can be found [here](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/).\n",
    "\n",
    "\n",
    "Option 1 (Amazon CloudWatch): You can go to the [Amazon CloudWatch](https://aws.amazon.com/cloudwatch/) metrics dashboard from your account to monitor and visualize the algorithm metrics as well as track the GPU and CPU usage. The training jobs details page has a direct link to the Amazon CloudWatch metrics dashboard for the metrics emitted by the training algorithm.\n",
    "\n",
    "Option 2 (Amazon SageMaker Python SDK API): You can also visualize the metrics inline in your Amazon SageMaker Jupyter notebooks using the Amazon SageMaker Python SDK APIs. Please, refer to the section titled *Visualize algorithm metrics for training* in `train.ipynb`.\n",
    "\n",
    "Option 3: Tensorboard TODO @annaluo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Plot metrics using Amazon SageMaker Python SDK API\n",
    "\n",
    "You need to wait for the training job to allocate computational resources before viewing the logs. \n",
    "\n",
    "*Note: If you get a warning that the logs do not exist, wait for a few minutes and re-run the cell.*\n",
    "\n",
    "*Note 2: If you are getting an import error from Tensorflow, open a terminal and type `source activate tensorflow2_p36`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For usage, refer to https://sagemaker.readthedocs.io/en/stable/api/training/analytics.html#\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from source.utils.inference import get_latest_sagemaker_training_job\n",
    "\n",
    "# Get last training job_names \n",
    "eval_training_jobs = [get_latest_sagemaker_training_job(name_contains=\"{}-{}\".format(\n",
    "    job_name_prefix, env)) for env in envs_to_run]\n",
    "\n",
    "for training_job_name, env in zip(eval_training_jobs, envs_to_run):\n",
    "    metric_names = ['episode_reward_mean', 'timesteps_total']\n",
    "\n",
    "    # download the metrics on cloudwatch\n",
    "    metrics_dataframe = TrainingJobAnalytics(training_job_name=training_job_name, metric_names=metric_names).dataframe()\n",
    "\n",
    "    # pivot to get the metrics\n",
    "    metrics_dataframe= metrics_dataframe.pivot(index='timestamp', columns='metric_name', values='value')\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = metrics_dataframe.plot(kind='line', figsize=(12, 5), x='timesteps_total', y='episode_reward_mean', style='b.', legend=False)\n",
    "    ax.set_ylabel('Episode Reward Mean')\n",
    "    ax.set_xlabel('Timesteps')\n",
    "    ax.set_title(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollout the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can choose your to use the previous trained model data or input your own path to model.tar.gz created in a previous training job\n",
    "rollout_env = \"coinrun\"\n",
    "lastest_training_job = get_latest_sagemaker_training_job(name_contains=\"{}-{}\".format(\n",
    "    job_name_prefix, rollout_env))\n",
    "model_data = \"{}/{}/output/model.tar.gz\".format(s3_output_path, lastest_training_job)\n",
    "\n",
    "# model_data = estimator.model_data\n",
    "\n",
    "# model_data = \"s3://<path to your model_data>/model.tar.gz\"\n",
    "\n",
    "bucket_key = \"/\".join(model_data.split(\"/\")[-3:])\n",
    "\n",
    "print(\"The trained model is located in {}\".format(model_data))\n",
    "print(\"bucket key is {}\".format(bucket_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model from S3\n",
    "s3 = boto3.client('s3')\n",
    "with open('model.tar.gz', 'wb') as data:\n",
    "    s3.download_fileobj(s3_bucket, bucket_key, data)\n",
    "# Unpack the model\n",
    "!mkdir model\n",
    "!tar -C model -xf model.tar.gz\n",
    "\n",
    "# Print the parameters in the model\n",
    "!cat model/params.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import gym\n",
    "from IPython import display\n",
    "\n",
    "from source.utils.inference import get_action\n",
    "\n",
    "model_filepath = \"model/1/\"\n",
    "episodes_to_run = 2000\n",
    "env_name = \"coinrun\"\n",
    "net = tf.saved_model.load(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"procgen:procgen-{}-v0\".format(rollout_env), start_level=0, num_levels=1, render_mode=\"rgb_array\")\n",
    "\n",
    "obs = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "plt.axis('off')\n",
    "\n",
    "total_reward = 0.0\n",
    "prev_action = None\n",
    "prev_reward = None\n",
    "for i in range(episodes_to_run):\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = get_action(net, obs, prev_action, prev_reward)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    prev_action = action\n",
    "    prev_reward = reward\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "print(\"Total reward is {}\".format(total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
